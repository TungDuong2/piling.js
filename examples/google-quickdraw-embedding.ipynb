{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Quick Draw Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "\n",
    "with open('data/full_simplified_teapot.ndjson') as f:\n",
    "    data = ndjson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'teapot',\n",
       " 'countrycode': 'US',\n",
       " 'timestamp': '2017-03-15 04:43:12.20679 UTC',\n",
       " 'recognized': True,\n",
       " 'key_id': '4699508627734528',\n",
       " 'drawing': [[[49,\n",
       "    38,\n",
       "    0,\n",
       "    11,\n",
       "    19,\n",
       "    29,\n",
       "    54,\n",
       "    75,\n",
       "    85,\n",
       "    92,\n",
       "    111,\n",
       "    119,\n",
       "    134,\n",
       "    158,\n",
       "    214,\n",
       "    228,\n",
       "    240,\n",
       "    249,\n",
       "    255,\n",
       "    254,\n",
       "    250,\n",
       "    235,\n",
       "    225,\n",
       "    198,\n",
       "    174,\n",
       "    157,\n",
       "    94,\n",
       "    40],\n",
       "   [104,\n",
       "    88,\n",
       "    70,\n",
       "    55,\n",
       "    51,\n",
       "    54,\n",
       "    82,\n",
       "    89,\n",
       "    89,\n",
       "    85,\n",
       "    53,\n",
       "    49,\n",
       "    49,\n",
       "    57,\n",
       "    66,\n",
       "    75,\n",
       "    88,\n",
       "    106,\n",
       "    131,\n",
       "    150,\n",
       "    161,\n",
       "    179,\n",
       "    185,\n",
       "    192,\n",
       "    191,\n",
       "    186,\n",
       "    151,\n",
       "    108]],\n",
       "  [[175, 169, 166, 164, 175, 192, 208, 218, 220, 216],\n",
       "   [56, 53, 44, 17, 3, 0, 11, 27, 54, 60]],\n",
       "  [[178, 172, 174, 183, 205], [52, 44, 26, 19, 17]]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw 126804 sketches...\n",
      "...drew 10000 sketches in 8.3 secs\n",
      "...drew 10000 sketches in 8.5 secs\n",
      "...drew 10000 sketches in 8.9 secs\n",
      "...drew 10000 sketches in 8.9 secs\n",
      "...drew 10000 sketches in 8.4 secs\n",
      "...drew 10000 sketches in 8.3 secs\n",
      "...drew 10000 sketches in 8.6 secs\n",
      "...drew 10000 sketches in 8.4 secs\n",
      "...drew 10000 sketches in 9.5 secs\n",
      "...drew 10000 sketches in 9.3 secs\n",
      "...drew 10000 sketches in 8.7 secs\n",
      "...drew 10000 sketches in 8.6 secs\n",
      "Done drawing in 1.8 min\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.draw import line_aa\n",
    "import time\n",
    "\n",
    "in_size = 256\n",
    "out_size = 64\n",
    "out_max = out_size - 1\n",
    "scaling = out_size / in_size\n",
    "\n",
    "sketches = np.zeros((len(data), out_size, out_size), dtype=np.float64)\n",
    "\n",
    "print(f'Draw {len(data)} sketches...')\n",
    "\n",
    "t = time.time()\n",
    "t0 = t\n",
    "o = 10000\n",
    "for s, sketch in enumerate(data):\n",
    "    if s % o == o - 1:\n",
    "        print(f'...drew {o} sketches in {(time.time()-t):.1f} secs')\n",
    "        t = time.time()\n",
    "    for stroke in sketch['drawing']:\n",
    "        xs, ys = stroke\n",
    "        for k in np.arange(1, len(xs)):            \n",
    "            i, j, val = line_aa(\n",
    "                min(out_max, round(ys[k-1] * scaling)),\n",
    "                min(out_max, round(xs[k-1] * scaling)),\n",
    "                min(out_max, round(ys[k] * scaling)),\n",
    "                min(out_max, round(xs[k] * scaling))\n",
    "            ) # i0, j0, i1, j1\n",
    "            sketches[s][i,j] += val\n",
    "\n",
    "print(f'Done drawing in {((time.time() - t0) / 60):.1f} min')\n",
    "\n",
    "sketches_flat = np.clip(sketches.reshape((sketches.shape[0], -1)), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Fritz/miniconda3/envs/pilingjs/lib/python3.7/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../miniconda3/envs/pilingjs/lib/python3.7/site-packages/umap/rp_tree.py\", line 135:\n",
      "@numba.njit(fastmath=True, nogil=True, parallel=True)\n",
      "def euclidean_random_projection_split(data, indices, rng_state):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/Fritz/miniconda3/envs/pilingjs/lib/python3.7/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../miniconda3/envs/pilingjs/lib/python3.7/site-packages/umap/utils.py\", line 409:\n",
      "@numba.njit(parallel=True)\n",
      "def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):\n",
      "^\n",
      "\n",
      "  current_graph, n_vertices, n_neighbors, max_candidates, rng_state\n",
      "/Users/Fritz/miniconda3/envs/pilingjs/lib/python3.7/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../miniconda3/envs/pilingjs/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "neighborhood = 0.001 # 1 promille\n",
    "n_neighbors = round(sketches_flat.shape[0] * neighborhood)\n",
    "\n",
    "embeddings = UMAP(n_neighbors=n_neighbors).fit_transform(sketches_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler((0.1, 0.9))\n",
    "scaled_embeddings = scaler.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Ebmedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, json \n",
    "\n",
    "f = codecs.open('data/full_simplified_teapot_umap_embedding.json', 'w', encoding='utf-8')\n",
    "json.dump(embeddings.tolist(), f, separators=(',', ':'), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pycountry\n",
    "\n",
    "# x, y, recognized, countrycode, num_strokes, mean_stroke_length\n",
    "features = np.zeros((embeddings.shape[0], 6))\n",
    "\n",
    "features[:, 0:2] = embeddings # x, y\n",
    "\n",
    "for i, drawing in enumerate(data):\n",
    "    features[i, 2] = drawing['recognized']\n",
    "    try:\n",
    "        features[i, 3] = pycountry.countries.get(alpha_2=drawing['countrycode']).numeric\n",
    "    except AttributeError:\n",
    "        features[i, 3] = 0\n",
    "    features[i, 4] = len(drawing['drawing'])\n",
    "    features[i, 5] = reduce(lambda a, b: a + len(b[0]), drawing['drawing'], 0) / len(drawing['drawing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features_scaled = MinMaxScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Sample Drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apricot import FeatureBasedSelection\n",
    "\n",
    "selector = FeatureBasedSelection(2000, concave_func='sqrt', optimizer='two-stage', n_jobs=-1, verbose=False)\n",
    "_, selection = selector.fit_transform(features_scaled, np.arange(features_scaled.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, json \n",
    "\n",
    "out = []\n",
    "\n",
    "for i in selection:\n",
    "    out.append({\n",
    "        'countryCode': data[i]['countrycode'],\n",
    "        'recognized': data[i]['recognized'],\n",
    "        'umapEmbedding': features_scaled[i, 0:2].tolist(),\n",
    "        'src': np.array(data[i]['drawing']).tolist(),\n",
    "    })\n",
    "\n",
    "f = codecs.open('data/teapot-umap-subsample.json', 'w', encoding='utf-8')\n",
    "json.dump(out, f, separators=(',', ':'), sort_keys=True, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
